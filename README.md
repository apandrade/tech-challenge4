# ğŸ“Œ  Tech Challenge 4 - AnÃ¡lise de VÃ­deo com DetecÃ§Ã£o de Pose e EmoÃ§Ãµes

Este projeto realiza **anÃ¡lise de vÃ­deo** utilizando **VisÃ£o Computacional e Aprendizado de MÃ¡quina** para identificar poses humanas, detectar emoÃ§Ãµes e relatar anomalias nos movimentos.  

## ğŸ› ï¸ Funcionalidades

- **DetecÃ§Ã£o de pose humana** usando **MediaPipe**  
- **IdentificaÃ§Ã£o de atividades** baseadas na posiÃ§Ã£o do corpo  
- **DetecÃ§Ã£o de emoÃ§Ãµes faciais** utilizando **DeepFace**  
- **Registro de anomalias nos movimentos**  
- **GeraÃ§Ã£o de relatÃ³rio** com estatÃ­sticas da anÃ¡lise  
- **Processamento de vÃ­deo** e salvamento de saÃ­da anotada  

---

## ğŸš€ Como Executar o Projeto

### 1ï¸âƒ£ Instale as dependÃªncias

Antes de rodar o cÃ³digo, instale as bibliotecas necessÃ¡rias, contidas no arquivo `requirements.txt`:

### 2ï¸âƒ£ Execute o script principal

Coloque um vÃ­deo chamado `input_video.mp4` na mesma pasta do script e rode:

```bash
python analisando-video.py
```

---

## ğŸ“š Bibliotecas Utilizadas

O cÃ³digo faz uso das seguintes bibliotecas:

| Biblioteca | FunÃ§Ã£o |
|------------|------------------------------------------------|
| `opencv-python` | Processamento de vÃ­deo e exibiÃ§Ã£o de saÃ­da |
| `mediapipe` | DetecÃ§Ã£o da pose humana |
| `deepface` | Reconhecimento facial e anÃ¡lise de emoÃ§Ãµes |
| `tqdm` | Barra de progresso durante o processamento |
| `numpy` | CÃ¡lculos matemÃ¡ticos para anÃ¡lise de poses |
| `os` | ManipulaÃ§Ã£o de diretÃ³rios e arquivos |
| `time` | MediÃ§Ã£o de tempo de execuÃ§Ã£o |

---

## ğŸ” Estrutura do CÃ³digo

### ğŸƒ DetecÃ§Ã£o de Pose (MediaPipe)

- **`detect_pose_and_anomalies(frame, pose_model, last_pose_landmarks, frame_index, anomalies)`**  
  â†’ Processa cada frame para detectar poses e registra anomalias nos movimentos.

- **`determine_activity(landmarks)`**  
  â†’ Analisa os pontos do corpo e classifica a atividade como "Em pÃ©", "Sentado", "Deitado", "Acenando", etc.

- **`calculate_pose_difference(pose1, pose2)`**  
  â†’ Compara poses para identificar mudanÃ§as bruscas que podem indicar anomalias.

### ğŸ˜€ DetecÃ§Ã£o de EmoÃ§Ãµes (DeepFace)

- **`detect_emotions(frame)`**  
  â†’ Analisa expressÃµes faciais e retorna as emoÃ§Ãµes detectadas.

- **`draw_emotions(frame, emotions)`**  
  â†’ Desenha caixas ao redor do rosto e exibe a emoÃ§Ã£o detectada no frame.

### ğŸ¥ Processamento de VÃ­deo

- **`process_video(video_path, output_path, report_path)`**  
  â†’ LÃª o vÃ­deo de entrada, analisa cada frame, salva um novo vÃ­deo com as anotaÃ§Ãµes e gera um relatÃ³rio.

### ğŸ“Š RelatÃ³rio Gerado

ApÃ³s a execuÃ§Ã£o, um **relatÃ³rio de anÃ¡lise** serÃ¡ salvo em:

```
output/summary_report.txt
```

Ele conterÃ¡:
- NÃºmero total de frames analisados
- Quantidade de anomalias detectadas
- EmoÃ§Ãµes mais comuns
- Frames onde anomalias ocorreram

---

## ğŸ“Œ Exemplo de SaÃ­da

ğŸ”¹ **VÃ­deo anotado:**  
- DetecÃ§Ã£o da pose com linhas e conexÃµes desenhadas  
- EmoÃ§Ãµes exibidas sobre os rostos detectados  
- Atividade classificada exibida no canto da tela  

ğŸ”¹ **RelatÃ³rio gerado:**  

```
Resumo da AnÃ¡lise do VÃ­deo
Total de frames analisados: 3000
NÃºmero de anomalias detectadas: 45
EmoÃ§Ãµes detectadas:
  feliz: 10 vezes
  neutro: 25 vezes
  surpreso: 5 vezes

Frames com anomalias:
123, 456, 789, ...
```

---

## ğŸ“ ObservaÃ§Ãµes

- O vÃ­deo de entrada deve estar na pasta do script e ser nomeado `input_video.mp4`.  
- O modelo pode ter dificuldades em detectar poses corretamente se a iluminaÃ§Ã£o estiver ruim ou houver muitas pessoas no vÃ­deo.  
- O script suporta **interrupÃ§Ã£o manual** (pressionando `Q` durante a execuÃ§Ã£o).

---

## ğŸ¤– Melhorias Futuras

- Melhorar detecÃ§Ã£o e avaliaÃ§Ã£o. 
- Melhorar a precisÃ£o da **detecÃ§Ã£o de anomalias** ajustando os **limiares de diferenÃ§a**.  
- Implementar suporte para **detecÃ§Ã£o de mÃºltiplas pessoas** no mesmo vÃ­deo.  
